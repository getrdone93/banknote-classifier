{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses the UCI banknote dataset\n",
    "- https://archive.ics.uci.edu/ml/datasets/banknote+authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "import itertools\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.stats import zscore\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/data_banknote_authentication.csv')\n",
    "feats = list(df)[:-1]\n",
    "df.drop_duplicates(keep='first', inplace=True, ignore_index=True, subset=feats)\n",
    "neg, pos = [df.loc[df['class'] == arg] for arg in (0, 1)]\n",
    "total = len(df)\n",
    "print(\"negative: {:.0%}, positive: {:.0%}\".format(len(neg) / total, len(pos) / total))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data\n",
    "for f in feats:\n",
    "    df.update({f: zscore(df[f])})\n",
    "\n",
    "#Plot standardized features\n",
    "xs = range(len(df))     \n",
    "args = [(f, xs, df[f], c) for f, c in zip(feats, ('ro', 'bo', 'go', 'yo'))]     \n",
    "for a in args:         \n",
    "    ar = a[1:]         \n",
    "    fig, ax = pyplot.subplots()         \n",
    "    ax.plot(*ar)\n",
    "    fig.suptitle(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The distributions of the features overlap from [-2, 2].\n",
    "- outliars for curtosis and entropy are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(kernel_regularizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=kernel_regularizer))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def complex_model(kernel_regularizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=4, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=kernel_regularizer))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#arguments for cross validation\n",
    "xs, ys = np.asarray(df[list(df)[:-1]]), np.asarray(df[list(df)[-1]])\n",
    "model_params = [(simple_model, {'epochs': [5, 10], 'batch_size': [3, 4],\n",
    "                                'verbose': [0], 'kernel_regularizer': ['l1', 'l2']}),\n",
    "                (complex_model, {'epochs': [10, 15], 'batch_size': [3, 4], 'verbose': [0],\n",
    "                                 'kernel_regularizer': ['l1', 'l2']})]\n",
    "train_params = {'epochs', 'verbose', 'batch_size'}\n",
    "build_model_params = {'kernel_regularizer'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The simple model is a vector of weights equal in length to the input vector\n",
    "- The complex model has two hidden layers with the first being a 3x4 matrix\n",
    "- ```model_params``` defines the model space, where each model's arguments will be expanded via cartesian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 fold cross validate each model in model space, return a data frame of results\n",
    "def evaluate(model_params, xs, ys, tr_params, bm_params):\n",
    "    st_kf = StratifiedKFold(n_splits=5)\n",
    "    row_keys = ['train_loss', 'train_accuracy', 'test_loss', 'test_accuracy', 'train_params', \n",
    "                'model_params', 'model_name', 'ys_ps', 'auc']\n",
    "    colors = ['b', 'g', 'c', 'm', 'y', 'k', 'r']\n",
    "    ci = 0\n",
    "    cv_results = {k: [] for k in row_keys}\n",
    "    ys_ps = {mod_func.__name__: [] for mod_func, _ in model_params}\n",
    "    for mod_func, params in model_params:\n",
    "        print(\"Training {}\".format(mod_func.__name__))\n",
    "        for ps in tqdm(list(ParameterGrid(params))):\n",
    "            for tr_ind, tst_ind in st_kf.split(xs, ys):\n",
    "                tr_x, tr_y = xs[tr_ind], ys[tr_ind]\n",
    "                tst_x, tst_y = xs[tst_ind], ys[tst_ind]\n",
    "                bmps = {k: ps[k] for k in bm_params}\n",
    "                tps = {k: ps[k] for k in tr_params}\n",
    "                train_model = mod_func(**bmps)\n",
    "                th = train_model.fit(tr_x, tr_y, **tps)\n",
    "                tr_l, tr_a = th.history['loss'][-1], th.history['accuracy'][-1]\n",
    "                tst_l, tst_a = train_model.evaluate(tst_x, tst_y, verbose=0)\n",
    "                \n",
    "                cv_results[row_keys[0]].append(tr_l)\n",
    "                cv_results[row_keys[1]].append(tr_a)\n",
    "                cv_results[row_keys[2]].append(tst_l)\n",
    "                cv_results[row_keys[3]].append(tst_a)\n",
    "                cv_results[row_keys[4]].append(tuple(tps.items()))\n",
    "                cv_results[row_keys[5]].append(tuple(bmps.items()))\n",
    "                cv_results[row_keys[6]].append(mod_func.__name__)\n",
    "                ys_ps = (tst_y, train_model.predict(tst_x), colors[ci])\n",
    "                cv_results[row_keys[7]].append(ys_ps)\n",
    "                fpr, tpr, _ = metrics.roc_curve(np.array(ys_ps[0]), np.array(ys_ps[1]))\n",
    "                cv_results[row_keys[8]].append(metrics.auc(fpr, tpr))\n",
    "                ci = (ci + 1) % len(colors)\n",
    "    return pd.DataFrame(cv_results)\n",
    "\n",
    "#Group by model and aggregate according columns\n",
    "def cv_results(cv_data):\n",
    "    agg_funcs = ['mean', 'std', 'min', 'max']\n",
    "    output = cv_data.groupby(['model_name', 'model_params', 'train_params'])\\\n",
    "    .agg({'test_accuracy': agg_funcs,\n",
    "          'train_accuracy': agg_funcs,\n",
    "          'test_loss': agg_funcs,\n",
    "          'train_loss': agg_funcs,\n",
    "          'model_name': ['first'],\n",
    "          'model_params': ['first'],\n",
    "          'train_params': ['first'],\n",
    "          'ys_ps': ['sum'],\n",
    "          'auc': agg_funcs})\n",
    "    return output\n",
    "\n",
    "cv_data = evaluate(model_params, xs, ys, train_params, build_model_params)\n",
    "res = cv_results(cv_data)\n",
    "\n",
    "#output results\n",
    "print(\"CV accuracy results:\\n\", res[[('test_accuracy', 'mean')]]\\\n",
    "      .sort_values(by=[('test_accuracy', 'mean')], ascending=False))\n",
    "\n",
    "print(\"\\nCV auc results:\\n\", res[[('auc', 'mean')]]\\\n",
    "      .sort_values(by=[('auc', 'mean')], ascending=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(ys_ps, model_name):\n",
    "    rates = [(fpr, tpr, th, c) for (fpr, tpr, th), c \\\n",
    "             in [(metrics.roc_curve(np.array(ys), np.array(ps)), c) for ys, ps, c in ys_ps]]\n",
    "    sk_fig, sk_ax = pyplot.subplots()\n",
    "    for f, t, _, c in rates:\n",
    "        sk_ax.plot(f, t, c)\n",
    "        sk_ax.plot([0, 1], [0, 1], '--r')\n",
    "        sk_ax.set_xlabel('FPR')\n",
    "        sk_ax.set_ylabel('TPR')\n",
    "        auc = [metrics.auc(fpr, tpr) for fpr, tpr, _, _ in rates]\n",
    "        avg_auc, std_auc, mi, mx = np.average(auc), np.std(auc), np.min(auc), np.max(auc)\n",
    "        sk_ax.legend([\"AVG AUC = {:.03}\\nSTD AUC = {:.03}\\nMIN AUC = {:.03}\\nMAX AUC = {:.03}\"\\\n",
    "                      .format(avg_auc, std_auc, mi, mx)], loc='lower right')\n",
    "        sk_fig.suptitle(model_name)\n",
    "\n",
    "#generate ROC curves\n",
    "def all_curves(cv_data):\n",
    "    assoc_ys_ps = lambda ys_ps: [tuple(ys_ps[si:si+3]) for si in range(0, len(ys_ps), 3)]\n",
    "    tup_to_str = lambda t: \"_\".join([\"{}_{}\".format(n, v) for n, v in t])\n",
    "    for r in range(len(cv_data)):\n",
    "        ys_ps = assoc_ys_ps(cv_data.iloc[r][('ys_ps', 'sum')])\n",
    "        fn_params = \"_\".join([tup_to_str(cv_data.iloc[r][(col, 'first')]) \\\n",
    "                              for col in ('model_params', 'train_params')])\n",
    "        fn = \"{}_{}\".format(cv_data.iloc[r][('model_name', 'first')], fn_params)\n",
    "        roc_curve(ys_ps, fn)\n",
    "\n",
    "all_curves(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The complex model looks to overfit the data as the ROC curves are nearly perfect.\n",
    "- The simple model with 5 epochs appears to not generalize as well as the other models.\n",
    "- The simple model with 10 epochs looks to be a good choice because it does as well as the complex model and has low variance. Batch size and regularization type appear to make little difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
